# Code-generating LLMs

This repository contains up-to-date progress on the course work:
1. Researched modern LLM code generation
2. Considered the behavior of models during quantization
3. Selected the optimal hyperparameters for passing the MBPP benchmark with different models
4. Compared the quality of model generation in Russian and English using HumavEval and RU HumanEval
5. The next step is to fine-tune the model for the task of finding errors in the code
